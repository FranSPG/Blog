{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "plt.style.use('ggplot')\n",
    "from datetime import datetime\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "pd.set_option('display.width', 1000)\n",
    "#pd.set_option('float_format', '{:f}'.format)\n",
    "#pd.set_option('display.mpl_style', 'default') # Make the graphs a bit prettier\n",
    "\n",
    "import pandas_profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import glob\n",
    "import natsort\n",
    "import re\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Limpieza </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molinetes_2014 = pd.read_csv('data/molinetes-2014.csv', sep=';')\n",
    "molinetes_2015 = pd.read_csv('data/molinetes-2015.csv', sep=',')\n",
    "molinetes_2016 = pd.read_csv('data/molinetes-2016.csv', sep=';')\n",
    "molinetes_2017 = pd.read_csv('data/molinetes-2017.csv', sep=';')\n",
    "molinetes_2018 = pd.read_csv('data/molinetes-2018.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molinetes_2014.drop(['HASTA', 'MOLINETE', 'PAX_PAGO', 'PAX_PASES_PAGOS', 'PAX_FRANQ'], axis=1, inplace=True)\n",
    "molinetes_2015.drop(['periodo', 'hasta', 'molinete', 'pax_pagos', 'pax_pases_pagos', 'pax_franq'], axis=1, inplace=True)\n",
    "molinetes_2016.drop(['PERIODO', 'HASTA', 'MOLINETE', 'PAX_PAGOS', 'PAX_PASES_PAGOS', 'PAX_FRANQ'], axis=1, inplace=True)\n",
    "molinetes_2017.drop(['PERIODO', 'HASTA', 'MOLINETE', 'PAX_PAGOS', 'PAX_PASES_PAGOS', 'PAX_FRANQ', 'ID'], axis=1, inplace=True)\n",
    "molinetes_2018.drop(['periodo', 'hasta', 'molinete', 'pax_pagos', 'pax_pases_pagos', 'pax_franq'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molinetes_2014.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [molinetes_2014, molinetes_2015, molinetes_2016, molinetes_2017, molinetes_2018]\n",
    "columnas = ['fecha', 'hora', 'linea', 'estacion', 'total']\n",
    "\n",
    "for df in dfs:\n",
    "    print(df.columns)\n",
    "    df.columns = columnas\n",
    "    df['timestamp'] = df['fecha'] +' '+ df['hora']\n",
    "    df.loc[(df['linea'] == 'LineaA') | (df['linea'] == 'A'), 'linea'] = 'LINEA_A'\n",
    "    df.loc[(df['linea'] == 'LineaB') | (df['linea'] == 'B'), 'linea'] = 'LINEA_B'\n",
    "    df.loc[(df['linea'] == 'LineaC') | (df['linea'] == 'C'), 'linea'] = 'LINEA_C'\n",
    "    df.loc[(df['linea'] == 'LineaD') | (df['linea'] == 'D'), 'linea'] = 'LINEA_D'\n",
    "    df.loc[(df['linea'] == 'LineaE') | (df['linea'] == 'E'), 'linea'] = 'LINEA_E'\n",
    "    df.loc[(df['linea'] == 'LineaH') | (df['linea'] == 'H'), 'linea'] = 'LINEA_H'\n",
    "    \n",
    "\n",
    "molinetes_2016.drop(molinetes_2016[molinetes_2016['linea'] == 'TALLER/PRUEBAS'].index, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molinetes_2014['timestamp'] = molinetes_2014['timestamp'] + ':00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molinetes_2017.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molinetes_2017['timestamp'] = molinetes_2017['timestamp'].str.replace('/', '-')\n",
    "molinetes_2016['timestamp'] = molinetes_2016['timestamp'].str.replace('/', '-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molinetes_2014['timestamp'] = pd.to_datetime(molinetes_2014['timestamp'])\n",
    "molinetes_2015['timestamp'] = pd.to_datetime(molinetes_2015['timestamp'])\n",
    "molinetes_2016['timestamp'] = pd.to_datetime(molinetes_2016['timestamp'], format='%d-%m-%Y %H:%M:%S')\n",
    "molinetes_2017['timestamp'] = pd.to_datetime(molinetes_2017['timestamp'], format='%d-%m-%Y %H:%M:%S')\n",
    "molinetes_2018['timestamp'] = pd.to_datetime(molinetes_2018['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molinetes_2014.to_csv('data/molinetes-2014-cleaned.csv')\n",
    "molinetes_2015.to_csv('data/molinetes-2015-cleaned.csv')\n",
    "molinetes_2016.to_csv('data/molinetes-2016-cleaned.csv')\n",
    "molinetes_2017.to_csv('data/molinetes-2017-cleaned.csv')\n",
    "molinetes_2018.to_csv('data/molinetes-2018-cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Análisis </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molinetes_2014 = pd.read_csv('data/molinetes-2014-cleaned.csv', sep=',', parse_dates=['timestamp'], index_col='timestamp',\n",
    "                            dtype={'linea':'category', 'estacion':'category', 'total':int},\n",
    "                             usecols=['timestamp', 'fecha', 'hora', 'linea', 'estacion', 'total'])\n",
    "molinetes_2015 = pd.read_csv('data/molinetes-2015-cleaned.csv', sep=',', parse_dates=['timestamp'], index_col='timestamp',\n",
    "                             dtype={'linea':'category', 'estacion':'category', 'total':int},\n",
    "                             usecols=['timestamp', 'fecha', 'hora', 'linea', 'estacion', 'total'])\n",
    "molinetes_2016 = pd.read_csv('data/molinetes-2016-cleaned.csv', sep=',', parse_dates=['timestamp'], index_col='timestamp',\n",
    "                             dtype={'linea':'category', 'estacion':'category', 'total':int},\n",
    "                             usecols=['timestamp', 'fecha', 'hora', 'linea', 'estacion', 'total'])\n",
    "molinetes_2017 = pd.read_csv('data/molinetes-2017-cleaned.csv', sep=',', parse_dates=['timestamp'], index_col='timestamp',\n",
    "                             dtype={'linea':'category', 'estacion':'category', 'total':int},\n",
    "                             usecols=['timestamp', 'fecha', 'hora', 'linea', 'estacion', 'total'])\n",
    "molinetes_2018 = pd.read_csv('data/molinetes-2018-cleaned.csv', sep=',', parse_dates=['timestamp'], index_col='timestamp', \n",
    "                             dtype={'linea':'category', 'estacion':'category', 'total':int},\n",
    "                             usecols=['timestamp', 'fecha', 'hora', 'linea', 'estacion', 'total'])\n",
    "\n",
    "dfs = [molinetes_2014, molinetes_2015, molinetes_2016, molinetes_2017, molinetes_2018]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molinetes_2014.año = 2014\n",
    "molinetes_2015.año = 2015\n",
    "molinetes_2016.año = 2016\n",
    "molinetes_2017.año = 2017\n",
    "molinetes_2018.año = 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molinetes_2018.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molinetes_2018.dropna(inplace=True)\n",
    "\n",
    "molinetes_2018['estacion'] = molinetes_2018['estacion'].str.lower()\n",
    "molinetes_2018['linea'] = molinetes_2018['linea'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molinetes_2018.loc[(molinetes_2018['estacion'] == 'agãâãâãâãâãâãâãâãâãâãâãâãâãâãâãâãâ¼ero') |\n",
    "                   (molinetes_2018['estacion'] == 'agãâãâãâãâãâãâãâãâ¼ero') |\n",
    "                   (molinetes_2018['estacion'] == 'agãâ¼ero') |\n",
    "                   (molinetes_2018['estacion'] == 'agãâãâ¼ero') |\n",
    "                   (molinetes_2018['estacion'] == 'agüero') |\n",
    "                   (molinetes_2018['estacion'] == 'agã¼ero'), 'estacion'] = 'aguero'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molinetes_2018.loc[(molinetes_2018['estacion'].str.contains('saenz')), 'estacion'] = 'saenz peña'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molinetes_2018.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proms = pd.DataFrame()\n",
    "\n",
    "df_proms['year'] = [2014, 2015, 2016, 2017, 2018]\n",
    "df_proms['prom_by_year'] = [df['total'].sum() for df in dfs]\n",
    "df_proms['prom_by_month'] = [df.groupby(df.index.month)['total'].sum().mean() for df in dfs]\n",
    "df_proms['prom_by_week'] = [df.groupby(df.index.week)['total'].sum().mean() for df in dfs]\n",
    "df_proms['prom_by_day'] = [df.groupby(df.index.floor('d'))['total'].sum().mean() for df in dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_proms.columns[1:]:\n",
    "    df_proms.plot.line(x='year', y=col, subplots=True)\n",
    "    plt.xticks(df_proms['year'].values)\n",
    "    plt.yticks(df_proms[col].values)\n",
    "    plt.ticklabel_format(style='plain')\n",
    "    plt.savefig('images/' + col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, df in enumerate(dfs):\n",
    "    explode = (0.05,0.05,0.05,0.05,0.05,0.05)\n",
    "    df_to_plot = df.groupby(df['linea'])['total'].sum()#.sort_values(ascending=False)\n",
    "    df_to_plot.plot.pie(autopct='%1.1f%%', startangle=90, pctdistance=0.85, explode = explode)\n",
    "    centre_circle = plt.Circle((0,0),0.70,fc='white')\n",
    "    fig = plt.gcf()\n",
    "    fig.gca().add_artist(centre_circle)\n",
    "\n",
    "    plt.title(str(2014 + idx))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('images/lineas' + str(idx))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "\n",
    "filenames = [img for img in glob.glob(\"images/lineas*.png\")]\n",
    "\n",
    "filenames.sort(key=lambda var:[int(x) if x.isdigit() else x for x in re.findall(r'[^0-9]|[0-9]+', var)])\n",
    "\n",
    "\n",
    "for image_path in filenames:\n",
    "    images.append(imageio.imread(image_path))\n",
    "    images.append(imageio.imread(image_path))\n",
    "    images.append(imageio.imread(image_path))\n",
    "    images.append(imageio.imread(image_path))\n",
    "    images.append(imageio.imread(image_path))\n",
    "    images.append(imageio.imread(image_path))\n",
    "    \n",
    "imageio.mimsave('images/lineas_evolucion.gif', images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molinetes_2018['weekday'] = molinetes_2018.index.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molinetes_2018.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "week_days = molinetes_2018.groupby([molinetes_2018.index.date, 'weekday'])['total'].sum().groupby('weekday').mean()\n",
    "week_days.index = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "week_days = week_days[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = week_days.plot(kind='barh', title='Pasajeros promedio por día')\n",
    "ax.set_xlabel('Pasajeros')\n",
    "ax.set_ylabel('Día')\n",
    "[ax.text(v, i, '{:.0f}'.format(v)) for i, v in enumerate(week_days)];\n",
    "plt.savefig('images/pasajeros_promedio_por_dia.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours_freq = molinetes_2018.groupby(pd.Grouper(freq='1H'))['total'].sum()\n",
    "hours_freq = hours_freq.groupby(hours_freq.index.hour).mean()\n",
    "hours_freq = hours_freq[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = hours_freq.plot(kind='barh', figsize=(25, 15), title='Pasajeros promedio por hora')\n",
    "ax.set_ylabel('Hora');\n",
    "ax.set_xlabel('Pasajeros')\n",
    "[ax.text(v, i, '{:.0f}'.format(v)) for i, v in enumerate(hours_freq)];\n",
    "plt.savefig('images/pasajeros_promedio_por_hora.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours_freq_by_station = pd.DataFrame(molinetes_2018.groupby([pd.Grouper(freq='1H'), 'estacion'])['total'].sum())\n",
    "hours_freq_by_station.reset_index(inplace=True)\n",
    "hours_freq_by_station.set_index('timestamp', inplace=True)\n",
    "hours_freq_by_station = hours_freq_by_station.groupby([hours_freq_by_station.index.hour, 'estacion']).mean()\n",
    "hours_freq_by_station.reset_index(inplace=True)\n",
    "hours_freq_by_station.set_index('timestamp', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours_freq_by_station = hours_freq_by_station[hours_freq_by_station['total'] == hours_freq_by_station.groupby('timestamp')['total'].transform(max)][12:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = hours_freq_by_station['total'].plot(kind='barh', figsize=(25, 15), title='Estación con más pasajeros promedio por hora')\n",
    "ax.set_ylabel('Hora')\n",
    "ax.set_xlabel('Pasajeros')\n",
    "[ax.text(x=row['total'] + 20, y=idx - 6, s='{:.0f} {}'.format(row['total'], row['estacion']), fontsize=15) for idx, row in hours_freq_by_station.iterrows()];\n",
    "plt.savefig('images/estaciones_por_hora.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(molinetes_2018['estacion'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dolar = pd.read_excel('data/dolar.xls', skiprows=3)\n",
    "dolar = dolar.loc[:, ['Fecha', 'Tipo de Cambio de Referencia - en Pesos - por Dólar']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dolar.rename(columns={'Tipo de Cambio de Referencia - en Pesos - por Dólar':'dolar'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dolar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dolar_grouped = pd.DataFrame(dolar.set_index('Fecha').groupby(pd.Grouper(freq='M'))['dolar'].mean())\n",
    "dolar_grouped.reset_index(inplace=True)\n",
    "dolar_grouped['año'] = [int(x[0]) for x in dolar_grouped['Fecha'].astype(str).str.split('-')];\n",
    "dolar_grouped['mes_numero'] = [int(x[1]) for x in dolar_grouped['Fecha'].astype(str).str.split('-')];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precio_boleto = pd.read_csv('data/registro-historico-del-precio-del-boleto.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molinetes_2014.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.DataFrame(columns=['total', 'año', 'precio', 'dolar', 'mes_numero', 'total_pesos', 'total_dolares'])\n",
    "\n",
    "for df in dfs:\n",
    "    month_freq = pd.DataFrame(df.groupby(pd.Grouper(freq='m'))['total'].sum())\n",
    "    month_freq['año'] = df.año\n",
    "    month_freq['mes'] = range(1, 13)\n",
    "    boleto_merge = pd.merge(month_freq, precio_boleto, how='left', left_on=['año', 'mes'], right_on=['año', 'mes_numero'])\n",
    "    boleto_merge.drop(['mes_numero', 'mes_y'], inplace=True, axis=1)\n",
    "    final_merge = pd.merge(boleto_merge, \n",
    "                       dolar_grouped[['dolar', 'año', 'mes_numero']], \n",
    "                       left_on=['mes_x', 'año'], \n",
    "                       right_on=['mes_numero', 'año'], \n",
    "                       how='left')\n",
    "    final_merge['total_pesos'] = final_merge['total'] * final_merge['precio']\n",
    "    final_merge['total_dolares'] = final_merge['total_pesos'] / final_merge['dolar']\n",
    "    final_merge.drop(['mes_x'], axis=1, inplace=True)\n",
    "    \n",
    "\n",
    "    df_final = df_final.append(final_merge, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.loc[57:, 'precio'] = 12.50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.loc[57:, 'total_pesos'] = df_final.loc[57:, 'total'] * df_final.loc[57:, 'precio']\n",
    "df_final.loc[57:, 'total_dolares'] = df_final.loc[57:, 'total_pesos'] / df_final.loc[57:, 'dolar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['año_mes'] = df_final['año'].astype(str) + '_' + df_final['mes_numero'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['año_mes'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "df_final[['total_pesos', 'total_dolares', 'año_mes']].plot(ax=ax, xticks=df_final.index, figsize=(30, 15), rot=45, fontsize=18)\n",
    "tick_idx = plt.xticks()[0]\n",
    "year_labels = df_final['año_mes'][tick_idx].values\n",
    "ax.set_xticklabels(year_labels)\n",
    "plt.ticklabel_format(style='plain', axis='y')\n",
    "plt.savefig('images/pesos_vs_dolar.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_grouped_by_year = df_final.groupby(['año'])['total_pesos', 'total_dolares'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_grouped_by_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
